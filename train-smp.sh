CUDA_VISIBLE_DEVICES=6 python -u train.py --distributed-no-spawn --no-epoch-checkpoints --keep-last-epochs 1 --keep-interval-updates 2  --seed 200 --lr 3e-5 --encoder-lr-scale 1 --decoder-lr-scale 30 --min-lr 1e-09  --max-epoch 5 --decoder-layers 2 --update-freq 4 --task bert_concat_decoder --arch transformer_bert  --token-types 15 --data /nas/qsj/data-smp/bert-jieba  --optimizer adam --adam-betas '(0.9, 0.999)'  --criterion cross_entropy  --lr-scheduler inverse_sqrt --decoder-head 8 --share-decoder-input-output-embed  --max-tokens 2000 --max-sentences 2 --tokenizer-dir /nas/qsj/bert-model/bert-base-chinese-jieba  --warmup-init-lr 1e-07 --min-lr 1e-08 --warmup-updates 10655  --no-progress-bar --weight-decay 0.01 --log-interval 1  --clip-norm 0.0  --save-interval-updates 3000  --save-dir /nas/qsj/checkpoints/SMP/smp-test-model
